name: Run web scraper

#on: 
#  schedule:
#    - cron: '30 12 * * *' # Run the workflow every day at 16:00 UTC+2
on: [workflow_dispatch]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: Install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Execute price scrape
        run: python prices_linux.py

      - name: Set up Git user
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      - name: Commit changes
        run: |
          git pull origin main --rebase  # Ensure the local copy is up-to-date with remote
          git add Price_data/*.csv
          git commit -m "Add new scraped data CSV files"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Required to authenticate the commit
      
      - name: Execute contract scrape
        run: python contracts_linux.py

      - name: Commit changes
        run: |          
          git pull origin main --rebase
          git add Contract_data/*.csv
          git commit -m "Add new scraped data CSV files"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Required to authenticate the commit
