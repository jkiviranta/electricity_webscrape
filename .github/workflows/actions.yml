name: Run web scraper

on: 
  schedule:
    - cron: '0 16 * * *' # Run the workflow every day at 18:00 UTC+2

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: Install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Execute price scrape
        run: python prices.py

      - name: Commit changes
        run: |
          git pull origin main --rebase  # Ensure the local copy is up-to-date with remote
          git add Price_data/*.csv
          git commit -m "Add new scraped data CSV files"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Required to authenticate the commit
      
      - name: Execute contract scrape
        run: python contracts.py

      - name: Commit changes
        run: |          
          git pull origin main --rebase  # Ensure the local copy is up-to-date with remote
          git add Price_data/*.csv
          git commit -m "Add new scraped data CSV files"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Required to authenticate the commit
