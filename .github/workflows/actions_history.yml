name: Run web scraper

#on: 
#  schedule:
#    - cron: '30 12 * * *' # Run the workflow every day at 12:30 UTC
on: [workflow_dispatch]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          
      - name: Install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Execute historical prices scrape
        run: python historical_prices_linux.py

      - name: Set up Git user
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      - name: Commit changes
        run: |
          git pull origin main --rebase  # Ensure the local copy is up-to-date with remote
          git add Price_history/*.csv
          git commit -m "Add new scraped data CSV files"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Required to authenticate the commit
